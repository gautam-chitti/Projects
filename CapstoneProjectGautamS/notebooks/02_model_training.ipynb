{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2a493e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "import joblib\n",
    "import os\n",
    "import warnings\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "29235dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "try:\n",
    "    X_scaled = pd.read_csv('../data/processed/scaled_features.csv')\n",
    "    X_pca = pd.read_csv('../data/processed/pca_features.csv').drop('Class', axis=1)\n",
    "    y = pd.read_csv('../data/processed/targets.csv').squeeze()\n",
    "    print(\"Processed data loaded successfully.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error loading processed data: {e}\")\n",
    "    print(\"Please ensure the data exploration notebook has been run first.\")\n",
    "    X_scaled, X_pca, y = pd.DataFrame(), pd.DataFrame(), pd.Series()\n",
    "\n",
    "spambase = fetch_ucirepo(id=94)\n",
    "X_raw = spambase.data.features\n",
    "y_raw = spambase.data.targets.squeeze()\n",
    "X_raw.columns = [re.sub(r'[\\[\\]<]', '_', col) for col in X_raw.columns]\n",
    "\n",
    "if not X_scaled.empty:\n",
    "    X_scaled.columns = [re.sub(r'[\\[\\]<]', '_', col) for col in X_scaled.columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "258dc615",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def training_and_evaluation(model, X, y, test_size=0.2, random_state=42):\n",
    "    if X.empty or y.empty:\n",
    "        print(f\"Skipping {model.__class__.__name__} due to missing data.\")\n",
    "        return None, 0, 0\n",
    "        \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state, stratify=y)\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Model: {model.__class__.__name__}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    return model, accuracy, precision\n",
    "\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5294b3a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training on Raw Data\n",
      "Model: LogisticRegression\n",
      "Accuracy: 0.9283\n",
      "Precision: 0.9160\n",
      "------------------------------\n",
      "Model: XGBClassifier\n",
      "Accuracy: 0.9490\n",
      "Precision: 0.9365\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTraining on Raw Data\")\n",
    "lr_raw = LogisticRegression(max_iter=1000, random_state=42)\n",
    "lr_raw_model, acc_lr_raw, prec_lr_raw = training_and_evaluation(lr_raw, X_raw, y_raw)\n",
    "results.append({'Data': 'Raw', 'Model': 'Logistic Regression', 'Accuracy': acc_lr_raw, 'Precision': prec_lr_raw, 'Model_Object': lr_raw_model})\n",
    "\n",
    "xgb_raw = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "xgb_raw_model, acc_xgb_raw, prec_xgb_raw = training_and_evaluation(xgb_raw, X_raw, y_raw)\n",
    "results.append({'Data': 'Raw', 'Model': 'XGBoost', 'Accuracy': acc_xgb_raw, 'Precision': prec_xgb_raw, 'Model_Object': xgb_raw_model})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "08d79683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training on Scaled Data\n",
      "Model: LogisticRegression\n",
      "Accuracy: 0.9294\n",
      "Precision: 0.9209\n",
      "------------------------------\n",
      "Model: XGBClassifier\n",
      "Accuracy: 0.9490\n",
      "Precision: 0.9365\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\nTraining on Scaled Data\")\n",
    "lr_scaled = LogisticRegression(max_iter=1000, random_state=42)\n",
    "lr_scaled_model, acc_lr_scaled, prec_lr_scaled = training_and_evaluation(lr_scaled, X_scaled, y)\n",
    "results.append({'Data': 'Scaled', 'Model': 'Logistic Regression', 'Accuracy': acc_lr_scaled, 'Precision': prec_lr_scaled, 'Model_Object': lr_scaled_model})\n",
    "\n",
    "xgb_scaled = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "xgb_scaled_model, acc_xgb_scaled, prec_xgb_scaled = training_and_evaluation(xgb_scaled, X_scaled, y)\n",
    "results.append({'Data': 'Scaled', 'Model': 'XGBoost', 'Accuracy': acc_xgb_scaled, 'Precision': prec_xgb_scaled, 'Model_Object': xgb_scaled_model})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cc008689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training on PCA Data\n",
      "Model: LogisticRegression\n",
      "Accuracy: 0.8599\n",
      "Precision: 0.8634\n",
      "------------------------------\n",
      "Model: XGBClassifier\n",
      "Accuracy: 0.8675\n",
      "Precision: 0.8414\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\nTraining on PCA Data\")\n",
    "lr_pca = LogisticRegression(random_state=42)\n",
    "lr_pca_model, acc_lr_pca, prec_lr_pca = training_and_evaluation(lr_pca, X_pca, y)\n",
    "results.append({'Data': 'PCA', 'Model': 'Logistic Regression', 'Accuracy': acc_lr_pca, 'Precision': prec_lr_pca, 'Model_Object': lr_pca_model})\n",
    "\n",
    "xgb_pca = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "xgb_pca_model, acc_xgb_pca, prec_xgb_pca = training_and_evaluation(xgb_pca, X_pca, y)\n",
    "results.append({'Data': 'PCA', 'Model': 'XGBoost', 'Accuracy': acc_xgb_pca, 'Precision': prec_xgb_pca, 'Model_Object': xgb_pca_model})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a4d13a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Performance Comparison\n",
      "     Data                Model  Accuracy  Precision\n",
      "1     Raw              XGBoost  0.948969   0.936464\n",
      "3  Scaled              XGBoost  0.948969   0.936464\n",
      "2  Scaled  Logistic Regression  0.929425   0.920904\n",
      "0     Raw  Logistic Regression  0.928339   0.915966\n",
      "5     PCA              XGBoost  0.867535   0.841360\n",
      "4     PCA  Logistic Regression  0.859935   0.863354\n",
      "\n",
      "Best Performing Model\n",
      "The best model is XGBoost (Raw) with:\n",
      "  - Accuracy: 0.9490\n",
      "  - Precision: 0.9365\n",
      "\n",
      "Best model saved to: ../models/best_spam_classifier.joblib\n"
     ]
    }
   ],
   "source": [
    "if results:\n",
    "    results_df = pd.DataFrame(results)\n",
    "    print(\"\\nModel Performance Comparison\")\n",
    "    print(results_df[['Data', 'Model', 'Accuracy', 'Precision']].sort_values(by=['Accuracy', 'Precision'], ascending=False))\n",
    "    best_model_entry = results_df.sort_values(by=['Accuracy', 'Precision'], ascending=False).iloc[0]\n",
    "    best_model = best_model_entry['Model_Object']\n",
    "    best_model_name = f\"{best_model_entry['Model']} ({best_model_entry['Data']})\"\n",
    "\n",
    "    print(f\"\\nBest Performing Model\")\n",
    "    print(f\"The best model is {best_model_name} with:\")\n",
    "    print(f\"  - Accuracy: {best_model_entry['Accuracy']:.4f}\")\n",
    "    print(f\"  - Precision: {best_model_entry['Precision']:.4f}\")\n",
    "    model_dir = '../models/'\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "    model_path = os.path.join(model_dir, 'best_spam_classifier.joblib')\n",
    "    joblib.dump(best_model, model_path)\n",
    "    print(f\"\\nBest model saved to: {model_path}\")\n",
    "else:\n",
    "    print(\"\\nModel training was skipped due to missing data. No model was saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048f7df0",
   "metadata": {},
   "source": [
    "#### HyperParameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "70b60acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split into training (3680 samples) and testing (921 samples).\n",
      "Calculated scale_pos_weight: 1.54\n",
      "\n",
      "Starting GridSearchCV to find the best hyperparameters for recall...\n",
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "\n",
      "GridSearchCV complete.\n",
      "Best parameters found: {'gamma': 0.1, 'learning_rate': 0.2, 'max_depth': 7, 'n_estimators': 100, 'scale_pos_weight': 2.5}\n",
      "\n",
      "--- Training and Evaluating Final Optimized Model ---\n",
      "\n",
      "Classification Report on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Not Spam       0.97      0.95      0.96       558\n",
      "        Spam       0.92      0.95      0.94       363\n",
      "\n",
      "    accuracy                           0.95       921\n",
      "   macro avg       0.94      0.95      0.95       921\n",
      "weighted avg       0.95      0.95      0.95       921\n",
      "\n",
      "\n",
      "Best tuned model saved to: ../models/best_tuned_spam_classifier.joblib\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_raw, y_raw, test_size=0.2, random_state=42, stratify=y_raw)\n",
    "print(f\"Data split into training ({len(X_train)} samples) and testing ({len(X_test)} samples).\")\n",
    "\n",
    "\n",
    "scale_pos_weight_value = y_train.value_counts()[0] / y_train.value_counts()[1]\n",
    "print(f\"Calculated scale_pos_weight: {scale_pos_weight_value:.2f}\")\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [5, 7],\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.1, 0.2],\n",
    "    'gamma': [0.1, 0.2],\n",
    "    'scale_pos_weight': [scale_pos_weight_value, 2.0, 2.5] \n",
    "}\n",
    "\n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "\n",
    "print(\"\\nStarting GridSearchCV to find the best hyperparameters for recall...\")\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_grid=param_grid,\n",
    "    scoring='recall', \n",
    "    cv=3,             \n",
    "    verbose=1,\n",
    "    n_jobs=-1         \n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nGridSearchCV complete.\")\n",
    "print(f\"Best parameters found: {grid_search.best_params_}\")\n",
    "\n",
    "\n",
    "print(\"\\n--- Training and Evaluating Final Optimized Model ---\")\n",
    "best_xgb_tuned = grid_search.best_estimator_\n",
    "y_pred_tuned = best_xgb_tuned.predict(X_test)\n",
    "\n",
    "print(\"\\nClassification Report on Test Set:\")\n",
    "print(classification_report(y_test, y_pred_tuned, target_names=['Not Spam', 'Spam']))\n",
    "\n",
    "model_path_tuned = os.path.join('../models/', 'best_tuned_spam_classifier.joblib')\n",
    "joblib.dump(best_xgb_tuned, model_path_tuned)\n",
    "print(f\"\\nBest tuned model saved to: {model_path_tuned}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
